# Лабораторная работа №1: Сумма элементов вектора
***

## Постановка задачи:

Реализовать алгоритм сложения элементов вектора.
 
Язык: __C++__

Входные данные: Вектор размером 1 000 ... 1 000 000 значений.

Выходные данные: сумма элементов вектора + время вычисления.

## Описание работы программы на CUDA:

Алгоритм распараллеливания заключается в том, что каждая нить будет прибавлять к общей сумме собственные элементы вектора.

Для сохранения результата частичной суммы для каждой нити создана переменная с разделяемой памятью:

```
__shared__ double cache[threadsPerBlock];
```

Вычисляем индекс для каждой нити и для нее определяем индекс в __cache__:

```
int tid = threadIdx.x + blockIdx.x * blockDim.x;
int cacheIndex = threadIdx.x;
```

Далее вычисляется частичная сумма элементов, а индекс нити увеличивается на общее количество нитей. 
Полученная частичная сумма сохраняется в части разделяемой памяти, выделенной для данной нити:

```
double tmp;
while (tid < n) {
	tmp += array[tid];
	tid += blockDim.x * gridDim.x;
}

cache[cacheIndex] = tmp;

__syncthreads();
```

В конце синхронизируются нити в данном блоке.

В конце для получения результата попарно суммируются частичные суммы в __cache__:

```
int i = blockDim.x / 2;
while (i != 0) {
	if (cacheIndex < i) {
		cache[cacheIndex] += cache[cacheIndex + i];
	}
	__syncthreads();
	i /= 2;
}
``` 

И каждый блок записывает свою сумму в глобальный массив:

```
if (cacheIndex == 0) {
	result[blockIdx.x] = cache[0];
}
```

Результатом вычисления суммы элементов в векторе будет сумма элементов вектора __result__.


## Пример работы программы:

Пример работы программы с количеством элементов вектора 100 000:

![Работа программы с количеством элементов вектора 100 000](https://github.com/DimaScientist/HPC/blob/main/VectorSum/images/example.jpg)


## Результаты экспериментов:

Обозначения:

* n - количество элементов вектора;

* t_gpu - время работы программы на CUDA (GPU);

* t_cpu - время работы программы на CPU;

* S = t_cpu / t_gpu - ускорение.

| параметр \ n | 1 000    | 10 000   | 50 000   | 100 000 | 500 000   | 1 000 000 | 5 000 000 | 10 000 000 |
| ------------ | -------- | -------- | -------- | ------- | --------- | --------- | --------- | ---------- |
| t_cpu, мс    |  2       | 2        | 2        | 2       | 3         | 4         | 17        | 30         |
| t_gpu, мс    | 0,042    | 0,043    | 0,045    | 0,049   | 0,051     | 0,057     | 0,081     | 0,094      |
| S            | 47,62    | 46,511   | 44,444   | 40,816  | 58,823    | 70,175    | 209,877   | 319,149    |

График зависимости времени работы программы на __CPU__ от количества элементов вектора:

![График зависимости времени работы программы на CPU от количества элементов вектора](https://github.com/DimaScientist/HPC/blob/main/VectorSum/images/cpu.png)

График зависимости времени работы программы на __GPU__ от количества элементов вектора:

![График зависимости времени работы программы на GPU от количества элементов вектора](https://github.com/DimaScientist/HPC/blob/main/VectorSum/images/gpu.png)

График зависимости __ускорения__ от размера матрицы:

![График зависимости ускорения от размера количества элементов вектора](https://github.com/DimaScientist/HPC/blob/main/VectorSum/images/boost.png)

## Выводы:

1. Программа с использованием CUDA (GPU) работает бысрее, чем на CPU;
2. С увеличением количества элементов вектора увеличивается и время работы программы. По графику ускорения видно, что время работы программы на CPU растёт быстрее, чем на GPU.
